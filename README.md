ğŸ“˜ Overview

Welcome to GenAI â€” a collection of my hands-on experiments in Generative AI.
This repository captures my learning journey across multiple sessions â€” from simple prompt-to-response generation to advanced document understanding and image intelligence using multimodal models.

âš¡ Sessions Summary
ğŸ§  Session 1 â€” Prompt â†’ Response Generation

Implemented text generation using Gemini Flash API.

Explored how LLMs handle direct prompts and structured outputs.

Notebook: LangChain_with_GeminiFlash_API.ipynb

âš™ï¸ Session 2 â€” LangChain & Workflow Automation

Integrated LangChain for pipeline-based LLM operations.

Experimented with prompt chaining, context management, and workflow automation.

Notebook: LangChain_with_GeminiFlash_API.ipynb (continuation of Session 2)

ğŸ“„ Session 3 â€” RAG Paper Reader Application

Built a RAG-based Reader to extract insights from unstructured documents like IEEE research papers.

Handled multi-column layouts, tables, and figures.

Developed logic to preserve document context for accurate LLM comprehension.

Folder: rag_paper_reader/

ğŸ–¼ï¸ Session 4 â€” AI Image Analyzer (Multimodal App)

Designed a Streamlit-based interactive web app using Gemini 2.0 Flash.

Allows users to upload any image and perform tasks like:

ğŸš€ Analyze Image: Ask custom questions about visual content.

ğŸ–¼ï¸ Generate Caption: Create meaningful, detailed captions.

ğŸ˜ƒ Emotion Detection: Identify the emotion or mood conveyed by the image.

Features include:

Sidebar settings for model selection & creativity control.

Downloadable responses and session-based chat history.

Polished UI with modern dark theme and animations.

App: ai_image_analyzer/

ğŸ§© Tech Stack

Python, Streamlit, Jupyter Notebooks

Gemini Flash API, LangChain, PyPDF, PIL

GitHub for version control & continuous progress tracking

ğŸš€ Goal

To create a progressive repository that explores and showcases Generative AI capabilities â€” from prompt engineering to RAG systems and multimodal AI applications.

ğŸŒŸ Whatâ€™s Next

More GenAI experiments coming soon â€” pushing boundaries with agents, voice AI, and advanced multimodal LLM workflows. Stay tuned ğŸ‘€
